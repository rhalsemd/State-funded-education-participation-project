{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","PATH = './drive/MyDrive/datasets/'\n","%cd /content/drive/MyDrive/groom_project2\n","%pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":72},"id":"nH_rsmuiYgrN","executionInfo":{"status":"ok","timestamp":1650016005527,"user_tz":-540,"elapsed":2558,"user":{"displayName":"조현수","userId":"06575509224308139266"}},"outputId":"f2a5238d-c868-4311-a9e0-b11a41006334"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/groom_project2\n"]},{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/groom_project2'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":1}]},{"cell_type":"code","source":["!pip install transformers wandb torchinfo"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xibvE0jImpbc","executionInfo":{"status":"ok","timestamp":1650016009336,"user_tz":-540,"elapsed":3812,"user":{"displayName":"조현수","userId":"06575509224308139266"}},"outputId":"3c578ee6-9e69-4c1b-eef2-80569a87a45c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n","Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.14)\n","Requirement already satisfied: torchinfo in /usr/local/lib/python3.7/dist-packages (1.6.5)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.10)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.3)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n"]}]},{"cell_type":"code","source":["!pip install --upgrade wandb"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cSll3FR5nU9f","executionInfo":{"status":"ok","timestamp":1650016013707,"user_tz":-540,"elapsed":4374,"user":{"displayName":"조현수","userId":"06575509224308139266"}},"outputId":"688e8a01-ebd9-4561-b9b8-7839e163d531"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.14)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.8)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.3)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.10)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n"]}]},{"cell_type":"markdown","metadata":{"id":"4V1iy8jrUCQR"},"source":["# Requirments"]},{"cell_type":"markdown","metadata":{"id":"wjNc9QiYxTgK"},"source":["## Import"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4497,"status":"ok","timestamp":1650016018201,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"f1Fm4Dx_xTFK"},"outputs":[],"source":["import os\n","import random\n","import math\n","import csv\n","import json\n","from statistics import mean\n","from typing import List, Tuple, Dict, Any\n","import uuid\n","\n","from tqdm.notebook import tqdm\n","from easydict import EasyDict as edict\n","\n","import numpy as np\n","from sklearn.preprocessing import StandardScaler\n","import matplotlib.pyplot as plt\n","\n","import wandb\n","\n","import torch\n","from torch.utils.data import DataLoader\n","from torch.nn.utils import clip_grad_norm_\n","from torch.nn.utils.rnn import pad_sequence\n","import torch.nn.functional as F\n","\n","from torchinfo import summary\n","\n","from transformers import ElectraModel, ElectraTokenizer, ElectraForQuestionAnswering, AutoModelForQuestionAnswering, AutoTokenizer, "]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1650016018201,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"3Xzif3OL_oAC"},"outputs":[],"source":["for name in 'models', 'submissions':\n","    os.makedirs(name, exist_ok=True)"]},{"cell_type":"markdown","metadata":{"id":"aZI1eMrCRjLY"},"source":["# Set Arguments, Hyper-parameters"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1650016018202,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"j3W659v9z1Vl","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ca4d0b66-ad59-4f17-903d-3c112e7c5d30"},"outputs":[{"output_type":"stream","name":"stdout","text":["kobert_v2_ep10_max1024_lr6e-05_634\n"]}],"source":["args = edict({'w_project': 'test_project',\n","              'w_entity': 'chohs1221',\n","              'learning_rate': 6e-5,\n","              'batch_size': {'train': 256,\n","                             'eval': 4,\n","                             'test': 256},\n","              'accumulate': 128,\n","              'epochs': 10,\n","              'seed': 42,\n","              # 'model_name': 'monologg/koelectra-base-v3-discriminator',\n","            #   'model_name': 'monologg/kobigbird-bert-base',\n","              'model_name': 'kobert-base-v1',\n","              'max_length': 1024})\n","# args['NAME'] = ''f'koelectra_ep{args.epochs}_lr{args.learning_rate}_{random.randrange(0, 1024)}'\n","args['NAME'] = ''f'kobert_v2_ep{args.epochs}_max{args.max_length}_lr{args.learning_rate}_{random.randrange(0, 1024)}'\n","print(args.NAME)"]},{"cell_type":"markdown","metadata":{"id":"EitWXKJmRw1b","toc-hr-collapsed":true},"source":["# Initialize"]},{"cell_type":"markdown","metadata":{"id":"51HhCeCTTDw5"},"source":["## Wandb"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DcDDby3eWOHd","executionInfo":{"status":"ok","timestamp":1650016020629,"user_tz":-540,"elapsed":2431,"user":{"displayName":"조현수","userId":"06575509224308139266"}},"outputId":"cc5a4c36-929e-4ec9-a390-07ff81aa5dbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchohs1221\u001b[0m (use `wandb login --relogin` to force relogin)\n"]}],"source":["!wandb login"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":109},"executionInfo":{"elapsed":7009,"status":"ok","timestamp":1650016027634,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"OACaHe-L-P-c","outputId":"cb1aaa63-bf20-4ad7-a2f3-ca5379318331"},"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mchohs1221\u001b[0m (use `wandb login --relogin` to force relogin)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.14"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/MyDrive/groom_project2/wandb/run-20220415_094702-1dum5wwt</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/chohs1221/test_project/runs/1dum5wwt\" target=\"_blank\">major-energy-29</a></strong> to <a href=\"https://wandb.ai/chohs1221/test_project\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/html":["<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/chohs1221/test_project/runs/1dum5wwt?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"],"text/plain":["<wandb.sdk.wandb_run.Run at 0x7ff95130fb10>"]},"metadata":{},"execution_count":8}],"source":["wandb.init(project = args.w_project, entity = args.w_entity)"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1650016027634,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"kB3HPxSa-TIn"},"outputs":[],"source":["wandb.run.name = args.NAME\n","wandb.config.learning_rate = args.learning_rate\n","wandb.config.epochs = args.epochs\n","wandb.config.batch_size = args.batch_size"]},{"cell_type":"markdown","metadata":{"id":"F6uJSyQCSEoa"},"source":["## Seed"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1650016027635,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"j9b17md7VKba"},"outputs":[],"source":["def seed_everything(seed):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)  # type: ignore\n","    torch.backends.cudnn.deterministic = True  # type: ignore\n","    torch.backends.cudnn.benchmark = True  # type: ignore\n","\n","seed_everything(args.seed)"]},{"cell_type":"markdown","metadata":{"id":"YbKj9juZVV7W","tags":[]},"source":["## Tokenizer"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":474},"executionInfo":{"elapsed":1139,"status":"error","timestamp":1650016028770,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"Sm8pjc33VKYg","outputId":"d5654820-21ab-48c1-fe29-c4fc4c671150"},"outputs":[{"output_type":"error","ename":"OSError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRepositoryNotFoundError\u001b[0m                   Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mget_file_from_repo\u001b[0;34m(path_or_repo, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only)\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies, resume_download, user_agent, extract_compressed_file, force_extract, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m             \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies, etag_timeout, resume_download, user_agent, use_auth_token, local_files_only)\u001b[0m\n\u001b[1;32m    485\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_redirects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0metag_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             \u001b[0m_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m             \u001b[0metag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"X-Linked-Etag\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ETag\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36m_raise_for_status\u001b[0;34m(request)\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0merror_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"RepoNotFound\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"404 Client Error: Repository Not Found for url: {request.url}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0merror_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"EntryNotFound\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRepositoryNotFoundError\u001b[0m: 404 Client Error: Repository Not Found for url: https://huggingface.co/kobert-base-v1/resolve/main/tokenizer_config.json","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-b70b9e77af60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# tokenizer = ElectraTokenizer.from_pretrained(args.model_name)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;31m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0mtokenizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m         \u001b[0mconfig_tokenizer_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokenizer_class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mtokenizer_auto_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, **kwargs)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0muse_auth_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_auth_token\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mlocal_files_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocal_files_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m     )\n\u001b[1;32m    343\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresolved_config_file\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mget_file_from_repo\u001b[0;34m(path_or_repo, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only)\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mRepositoryNotFoundError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m         raise EnvironmentError(\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0;34mf\"{path_or_repo} is not a local folder and is not a valid model identifier \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m             \u001b[0;34m\"listed on 'https://huggingface.co/models'\\nIf this is a private repository, make sure to \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;34m\"pass a token having permission to this repo with `use_auth_token` or log in with \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOSError\u001b[0m: kobert-base-v1 is not a local folder and is not a valid model identifier listed on 'https://huggingface.co/models'\nIf this is a private repository, make sure to pass a token having permission to this repo with `use_auth_token` or log in with `huggingface-cli login` and pass `use_auth_token=True`."]}],"source":["# tokenizer = ElectraTokenizer.from_pretrained(args.model_name)\n","tokenizer = AutoTokenizer.from_pretrained(args.model_name)"]},{"cell_type":"markdown","metadata":{"id":"UEQiDROgVXmg","tags":[]},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":530,"status":"aborted","timestamp":1650016028762,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"ZJ-003lak8sj"},"outputs":[],"source":["# model = ElectraForQuestionAnswering.from_pretrained(args.model_name)\n","model = AutoModelForQuestionAnswering.from_pretrained(args.model_name)\n","# summary(model, (args.batch_size.train//args.accumulate, args.max_length), dtypes=['torch.IntTensor'], device='cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":530,"status":"aborted","timestamp":1650016028763,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"4OoYuu2ckzJ6"},"outputs":[],"source":["model.cuda();"]},{"cell_type":"markdown","metadata":{"id":"9hCiOQO4VYqM","tags":[]},"source":["## Optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":530,"status":"aborted","timestamp":1650016028763,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"TonS9AsIVQlv"},"outputs":[],"source":["optimizer = torch.optim.AdamW(model.parameters(), lr=args.learning_rate)"]},{"cell_type":"markdown","metadata":{"id":"MlKUCHM9SUim","tags":[],"toc-hr-collapsed":true},"source":["# Datasets"]},{"cell_type":"markdown","metadata":{"id":"-SPF2-SSVoT5"},"source":["## Load, Split"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":530,"status":"aborted","timestamp":1650016028763,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"xoiHRyTOugMj"},"outputs":[],"source":["class KoMRC:\n","    def __init__(self, data, indices: List[Tuple[int, int, int]]):\n","        self._data = data\n","        self._indices = indices\n","\n","\n","    # Json을 불러오는 메소드\n","    @classmethod\n","    def load(cls, file_path: str):\n","        with open(file_path, 'r', encoding='utf-8') as fd:\n","            data = json.load(fd)\n","\n","        indices = []\n","        for d_id, document in enumerate(data['data']):\n","            for p_id, paragraph in enumerate(document['paragraphs']):\n","                for q_id, _ in enumerate(paragraph['qas']):\n","                    indices.append((d_id, p_id, q_id))\n","        \n","        return cls(data, indices)\n","\n","    # Json을 불러오는 메소드\n","    @classmethod\n","    def loads(cls, *file_path: str):\n","        datas = {'data': []}\n","        indices = []\n","        \n","        for f in file_path:\n","            with open(f, 'r', encoding='utf-8') as fd:\n","                data = json.load(fd)\n","            datas['data'] += data['data']\n","            \n","        for d_id, document in enumerate(datas['data']):\n","            for p_id, paragraph in enumerate(document['paragraphs']):\n","                for q_id, _ in enumerate(paragraph['qas']):\n","                    indices.append((d_id, p_id, q_id))\n","\n","        return cls(datas, indices)\n","\n","    # 데이터 셋을 잘라내는 메소드\n","    @classmethod\n","    def split(cls, dataset, eval_ratio: float=.016108):\n","        indices = list(dataset._indices)\n","        random.shuffle(indices)\n","        train_indices = indices[int(len(indices) * eval_ratio):]\n","        eval_indices = indices[:int(len(indices) * eval_ratio)]\n","\n","        return cls(dataset._data, train_indices), cls(dataset._data, eval_indices)\n","\n","\n","    def __getitem__(self, index: int) -> Dict[str, Any]:\n","        d_id, p_id, q_id = self._indices[index]\n","        paragraph = self._data['data'][d_id]['paragraphs'][p_id]\n","\n","        qa = paragraph['qas'][q_id]\n","\n","        if 'guid' in qa:\n","            guid = qa['guid']\n","        else:\n","            guid = uuid.uuid4().hex\n","\n","        context = paragraph['context'].replace('\\n', 'n').replace('\\xad', ' ').replace('\\xa0', ' ').replace('\\u200b', ' ')\n","\n","        question = qa['question'].replace('\\n', 'n').replace('\\xad', ' ').replace('\\xa0', ' ').replace('\\u200b', ' ')\n","\n","        answers = qa['answers']\n","        if answers != None:\n","            for a in answers:\n","                a['text'] = a['text'].replace('\\n', 'n').replace('\\xad', ' ').replace('\\xa0', ' ').replace('\\u200b', ' ')\n","        else:\n","            answers = None\n","\n","\n","        return {'guid': guid,\n","            'context': context,\n","            'question': question,\n","            'answers': answers\n","        }\n","\n","    def __len__(self) -> int:\n","        return len(self._indices)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":531,"status":"aborted","timestamp":1650016028764,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"CDu4gwv_ugKW"},"outputs":[],"source":["dataset1 = KoMRC.load('./datasets2/train.json')\n","dataset2 = KoMRC.load('./datasets2/ko_nia_normal_squad_all.json')\n","dataset3 = KoMRC.load('./datasets2/ko_wiki_v1_squad.json')\n","print(\"Number of Samples:\", len(dataset1), len(dataset2), len(dataset3))"]},{"cell_type":"markdown","metadata":{"id":"AaAHVuoEVs32"},"source":["## Tokenize & Tag Token Positions"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":532,"status":"aborted","timestamp":1650016028765,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"AluNiOayugGE"},"outputs":[],"source":["class TokenizedKoMRC(KoMRC):\n","    def __init__(self, data, indices: List[Tuple[int, int, int]]) -> None:\n","        super().__init__(data, indices)\n","        self._tokenizer = tokenizer\n","\n","\n","    def _tokenize_with_position(self, sentence: str) -> List[Tuple[str, Tuple[int, int]]]:\n","        position = 0\n","        tokens = []\n","\n","        sentence_tokens = []\n","        for word in sentence.split():\n","            if '[UNK]' in tokenizer.tokenize(word):\n","                sentence_tokens.append(word)\n","            else:\n","                sentence_tokens += tokenizer.tokenize(word)\n","        \n","        for morph in sentence_tokens:\n","            if len(morph) > 2:\n","                if morph[:2] == '##':\n","                    morph = morph[2:]\n","\n","            position = sentence.find(morph, position)\n","            tokens.append((morph, (position, position + len(morph))))\n","            position += len(morph)\n","            \n","        return tokens\n","            \n","\n","    def __getitem__(self, index: int) -> Dict[str, Any]:\n","        sample = super().__getitem__(index)\n","        # sample = {'guid': guid, 'context': context, 'question': question, 'answers': answers}\n","\n","        context, position = zip(*self._tokenize_with_position(sample['context']))\n","        context, position = list(context), list(position)\n","\n","        question = self._tokenizer.tokenize(sample['question'])\n","\n","        if sample['answers'] is not None:\n","            answers = []\n","            for answer in sample['answers']:\n","                for start, (position_start, position_end) in enumerate(position):\n","                    if position_start <= answer['answer_start'] < position_end:\n","                        break\n","                else:\n","                    print(context, answer)\n","                    print(answer['guid'])\n","                    print(answer['answer_start'])\n","                    raise ValueError(\"No mathced start position\")\n","\n","                target = ''.join(answer['text'].split(' '))\n","                source = ''\n","                for end, morph in enumerate(context[start:], start):\n","                    source += morph\n","                    if target in source:\n","                        break\n","                else:\n","                    print(context, answer)\n","                    print(answer['guid'])\n","                    print(answer['answer_start'])\n","                    raise ValueError(\"No Matched end position\")\n","\n","                answers.append({'start': start, 'end': end})\n","\n","        else:\n","            answers = None\n","        \n","        return {\n","            'guid': sample['guid'],\n","            'context_original': sample['context'],\n","            'context_position': position,\n","            'question_original': sample['question'],\n","            'context': context,\n","            'question': question,\n","            'answers': answers,\n","            'answers_text': sample['answers'][0]['text']\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":532,"status":"aborted","timestamp":1650016028765,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"K3Cu4vU1ugD2"},"outputs":[],"source":["dataset = TokenizedKoMRC.loads('./datasets2/train.json', './datasets2/ko_nia_normal_squad_all.json', './datasets2/ko_wiki_v1_squad.json')\n","train_dataset, dev_dataset = TokenizedKoMRC.split(dataset)\n","\n","dev_answers = [dev_dataset[i]['answers_text'] for i in range(len(dev_dataset))]\n","\n","print(\"Number of Train Samples:\", len(train_dataset))\n","print(\"Number of Dev Samples:\", len(dev_dataset))\n","# print(sample['context'][sample['answers'][0]['start']:sample['answers'][0]['end']+1])"]},{"cell_type":"markdown","metadata":{"id":"5NQ6g-qhV_7g"},"source":["## Input"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":532,"status":"aborted","timestamp":1650016028765,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"GyN44Vg-uf-Y"},"outputs":[],"source":["class Indexer:\n","    def __init__(self, vocabs: List[str], max_length: int=args.max_length):\n","        self.max_length = max_length\n","        self.vocabs = vocabs\n","\n","    @property\n","    def vocab_size(self):\n","        return len(self.vocabs)\n","    @property\n","    def pad_id(self):\n","        return tokenizer.vocab['[PAD]']\n","    @property\n","    def unk_id(self):\n","        return tokenizer.vocab['[UNK]']\n","    @property\n","    def cls_id(self):\n","        return tokenizer.vocab['[CLS]']\n","    @property\n","    def sep_id(self):\n","        return tokenizer.vocab['[SEP]']\n","\n","\n","    def sample2ids(self, sample: Dict[str, Any],) -> Dict[str, Any]:\n","        context = [tokenizer.convert_tokens_to_ids(token) for token in sample['context']]\n","        question = [tokenizer.convert_tokens_to_ids(token) for token in sample['question']]\n","\n","        context = context[:self.max_length-len(question)-3]             # Truncate context\n","        \n","        input_ids = [self.cls_id] + question + [self.sep_id] + context + [self.sep_id]\n","        token_type_ids = [0] * (len(question) + 1) + [1] * (len(context) + 2)\n","\n","        if sample['answers'] is not None:\n","            answer = sample['answers'][0]\n","            start = min(len(question) + 2 + answer['start'], self.max_length - 1)\n","            end = min(len(question) + 2 + answer['end'], self.max_length - 1)\n","        else:\n","            start = None\n","            end = None\n","\n","        return {\n","            'guid': sample['guid'],\n","            'context': sample['context_original'],\n","            'question': sample['question_original'],\n","            'position': sample['context_position'],\n","            'input_ids': input_ids,\n","            'token_type_ids': token_type_ids,\n","            'start': start,\n","            'end': end\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":533,"status":"aborted","timestamp":1650016028766,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"grrjgBHWuf8H"},"outputs":[],"source":["indexer = Indexer(list(tokenizer.vocab.keys()))"]},{"cell_type":"markdown","metadata":{"id":"6gLlDcdhWMVy"},"source":["## Attention Mask"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":532,"status":"aborted","timestamp":1650016028766,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"R2nGyyJLuf54"},"outputs":[],"source":["class IndexerWrappedDataset:\n","    def __init__(self, dataset: TokenizedKoMRC, indexer: Indexer) -> None:\n","        self._dataset = dataset\n","        self._indexer = indexer\n","\n","    def __len__(self) -> int:\n","        return len(self._dataset)\n","    \n","    def __getitem__(self, index: int) -> Dict[str, Any]:\n","        sample = self._indexer.sample2ids(self._dataset[index])\n","        sample['attention_mask'] = [1] * len(sample['input_ids'])\n","\n","        return sample"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":532,"status":"aborted","timestamp":1650016028766,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"g5ee_MDquf3p"},"outputs":[],"source":["indexed_train_dataset = IndexerWrappedDataset(train_dataset, indexer)\n","indexed_dev_dataset = IndexerWrappedDataset(dev_dataset, indexer)"]},{"cell_type":"markdown","metadata":{"id":"BrnFWwNFWydX"},"source":["## Collate"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":532,"status":"aborted","timestamp":1650016028766,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"Pp4TTU5Oufy-"},"outputs":[],"source":["class Collator:\n","    def __init__(self, indexer: Indexer) -> None:\n","        self._indexer = indexer\n","\n","\n","    def __call__(self, samples: List[Dict[str, Any]]) -> Dict[str, torch.Tensor]:\n","        samples = {key: [sample[key] for sample in samples] for key in samples[0]}\n","\n","        for key in 'start', 'end':\n","            if samples[key][0] is None:\n","                samples[key] = None\n","            else:\n","                samples[key] = torch.tensor(samples[key], dtype=torch.long)\n","        \n","        for key in 'input_ids', 'attention_mask', 'token_type_ids':\n","            samples[key] = pad_sequence([torch.tensor(sample, dtype=torch.long) for sample in samples[key]],\n","                                        batch_first=True,\n","                                        padding_value=self._indexer.pad_id)\n","\n","        return samples"]},{"cell_type":"markdown","metadata":{"id":"uNj_C_6sSwpE"},"source":["## Data Loader"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":533,"status":"aborted","timestamp":1650016028767,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"SlVyogmMufwZ"},"outputs":[],"source":["collator = Collator(indexer)\n","train_loader = DataLoader(indexed_train_dataset,\n","                          batch_size = args.batch_size.train // args.accumulate,\n","                          shuffle = True,\n","                          collate_fn = collator,\n","                          num_workers = 2)\n","\n","dev_loader = DataLoader(indexed_dev_dataset,\n","                        batch_size = args.batch_size.eval,\n","                        shuffle = False,\n","                        collate_fn = collator,\n","                        num_workers = 2)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"aborted","timestamp":1650016028767,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"3lcvlUltufuC"},"outputs":[],"source":["batch = next(iter(train_loader))\n","batch = next(iter(dev_loader))\n","# print(batch['input_ids'])\n","# print(batch['input_ids'].shape)\n","# print(list(batch.keys()))"]},{"cell_type":"markdown","metadata":{"id":"m8bJH_DNRfVm"},"source":["# Train"]},{"cell_type":"markdown","metadata":{"id":"eAfQOTuPeuWN","toc-hr-collapsed":true},"source":["## Empty Cuda Cache"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"aborted","timestamp":1650016028767,"user":{"displayName":"조현수","userId":"06575509224308139266"},"user_tz":-540},"id":"6WREvLj-AARp"},"outputs":[],"source":["import gc\n","gc.collect()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TWF13uO0WOHl","executionInfo":{"status":"aborted","timestamp":1650016028767,"user_tz":-540,"elapsed":11,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"outputs":[],"source":["os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""]},{"cell_type":"markdown","metadata":{"id":"8tkYfToDenKV","tags":[],"toc-hr-collapsed":true},"source":["## Train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Rfm5X-bEufpW","tags":[],"executionInfo":{"status":"aborted","timestamp":1650016028768,"user_tz":-540,"elapsed":12,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"outputs":[],"source":["train_losses = []\n","dev_losses = []\n","\n","train_loss = []\n","dev_loss = []\n","\n","loss_accumulate = 0.\n","\n","best_model = [-1, int(1e9)]\n","\n","for epoch in range(args.epochs):\n","    print(\"Epoch\", epoch, '===============================================================================================================')\n","\n","    # Train    \n","    progress_bar_train = tqdm(train_loader, desc='Train')\n","    for i, batch in enumerate(progress_bar_train, 1):\n","        del batch['guid'], batch['context'], batch['question'], batch['position']\n","        batch = {key: value.cuda() for key, value in batch.items()}\n","        \n","        start = batch.pop('start')\n","        end = batch.pop('end')\n","        \n","        output = model(**batch)\n","\n","        start_logits = output.start_logits\n","        end_logits = output.end_logits\n","        \n","        loss = (F.cross_entropy(start_logits, start) + F.cross_entropy(end_logits, end)) / args.accumulate\n","        loss.backward()\n","\n","        loss_accumulate += loss.item()\n","\n","        del batch, start, end, start_logits, end_logits, loss\n","        \n","        if i % args.accumulate == 0:\n","            # clip_grad_norm_(model.parameters(), max_norm=5.)\n","            optimizer.step()\n","            optimizer.zero_grad(set_to_none=False)\n","\n","            train_loss.append(loss_accumulate)\n","            progress_bar_train.set_description(f\"Train - Loss: {loss_accumulate:.3f}\")\n","            loss_accumulate = 0.\n","        else:\n","            continue\n","\n","        if i % int(len(train_loader) / (args.accumulate * 50)) == 0:\n","            # Evaluation\n","            for batch in dev_loader:\n","                del batch['guid'], batch['context'], batch['question'], batch['position']\n","                batch = {key: value.cuda() for key, value in batch.items()}\n","\n","                start = batch.pop('start')\n","                end = batch.pop('end')\n","                \n","                model.eval()\n","                with torch.no_grad():\n","                    output = model(**batch)\n","                \n","                    start_logits = output.start_logits\n","                    end_logits = output.end_logits\n","                model.train()\n","\n","                loss = F.cross_entropy(start_logits, start) + F.cross_entropy(end_logits, end)\n","\n","                dev_loss.append(loss.item())\n","\n","                del batch, start, end, start_logits, end_logits, loss\n","\n","            train_losses.append(mean(train_loss))\n","            dev_losses.append(mean(dev_loss))\n","            train_loss = []\n","            dev_loss = []\n","\n","            \n","            if dev_losses[-1] <= best_model[1]:\n","                best_model = (epoch, dev_losses[-1])\n","                model.save_pretrained(f'models/{args.NAME}_{epoch}')\n","                \n","            wandb.log({\"train_loss\": train_losses[-1], \n","                       \"valid_loss\": dev_losses[-1]})\n","            \n","    print(f\"Train Loss: {train_losses[-1]:.3f}\")\n","    print(f\"Valid Loss: {dev_losses[-1]:.3f}\")\n","    print('- - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -')\n"]},{"cell_type":"markdown","metadata":{"id":"5NeU3ogjS2LZ","tags":[]},"source":["## Visualize Training"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3nDxYe7KufnH","executionInfo":{"status":"aborted","timestamp":1650016028768,"user_tz":-540,"elapsed":12,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"outputs":[],"source":["plt.plot(train_losses, label=\"Train Loss\")\n","plt.plot(dev_losses, label=\"Dev Loss\")\n","plt.xlabel(\"Step\")\n","plt.ylabel(\"Loss\")\n","plt.legend()\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"wJKrztCmXRBB"},"source":["# Test"]},{"cell_type":"markdown","metadata":{"id":"r4vjm5TrYP-S"},"source":["## Datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5f9hR0qsu9Ap","executionInfo":{"status":"aborted","timestamp":1650016028768,"user_tz":-540,"elapsed":12,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"outputs":[],"source":["test_dataset = TokenizedKoMRC.load('./datasets2/test.json')\n","indexer_test = Indexer(list(tokenizer.vocab.keys()))\n","indexed_test_dataset = IndexerWrappedDataset(test_dataset, indexer_test)\n","print(\"Number of Test Samples\", len(test_dataset))\n","# print(test_dataset[0])"]},{"cell_type":"markdown","metadata":{"id":"y8js2FfYYJR7"},"source":["## Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-_SqJRTyWOHm","executionInfo":{"status":"aborted","timestamp":1650016028768,"user_tz":-540,"elapsed":12,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"outputs":[],"source":["best_model[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nESvW3pKufkv","executionInfo":{"status":"aborted","timestamp":1650016028768,"user_tz":-540,"elapsed":12,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"outputs":[],"source":["model = AutoModelForQuestionAnswering.from_pretrained(f'models/{args.NAME}_{best_model[0]}')\n","model.cuda();\n","# summary(model, (args.batch_size.train//args.accumulate, args.max_length), dtypes=['torch.IntTensor'], device='cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nbM5uvjDufiJ","executionInfo":{"status":"aborted","timestamp":1650016028769,"user_tz":-540,"elapsed":13,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"outputs":[],"source":["for idx, sample in zip(range(1, 4), indexed_train_dataset):\n","    print(f'------{idx}------')\n","    print('Context:', sample['context'])\n","    print('Question:', sample['question'])\n","    \n","    input_ids, token_type_ids = [\n","        torch.tensor(sample[key], dtype=torch.long, device=\"cuda\")\n","        for key in (\"input_ids\", \"token_type_ids\")\n","    ]\n","    \n","    model.eval()\n","    with torch.no_grad():\n","        output = model(input_ids=input_ids[None, :], token_type_ids=token_type_ids[None, :])\n","\n","    start_logits = output.start_logits\n","    end_logits = output.end_logits\n","    start_logits.squeeze_(0), end_logits.squeeze_(0)\n","    \n","    start_prob = start_logits[token_type_ids.bool()][1:-1].softmax(-1)\n","    end_prob = end_logits[token_type_ids.bool()][1:-1].softmax(-1)\n","\n","    probability = torch.triu(start_prob[:, None] @ end_prob[None, :])\n","\n","    index = torch.argmax(probability).item()\n","    \n","    start = index // len(end_prob)\n","    end = index % len(end_prob)\n","    \n","    start_str = sample['position'][start][0]\n","    end_str = sample['position'][end][1]\n","\n","    print('Answer:', sample['context'][start_str:end_str])"]},{"cell_type":"markdown","metadata":{"id":"ZM7QK1lEWOHm"},"source":["## Evaluate valid"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_6f99OvxWOHm","executionInfo":{"status":"aborted","timestamp":1650016028769,"user_tz":-540,"elapsed":13,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"outputs":[],"source":["start_visualize = []\n","end_visualize = []\n","\n","dev_prediction = []\n","# for sample in tqdm(test_dataset, \"Testing\"):\n","for sample in tqdm(indexed_dev_dataset, \"Testing\"):\n","    input_ids, token_type_ids = [torch.tensor(sample[key], dtype=torch.long, device=\"cuda\") for key in (\"input_ids\", \"token_type_ids\")]\n","    # print(sample)\n","\n","    model.eval()\n","    with torch.no_grad():\n","        output = model(input_ids=input_ids[None, :], token_type_ids=token_type_ids[None, :])\n","\n","    start_logits = output.start_logits\n","    end_logits = output.end_logits\n","    start_logits.squeeze_(0), end_logits.squeeze_(0)\n","\n","    start_prob = start_logits[token_type_ids.bool()][1:-1].softmax(-1)\n","    end_prob = end_logits[token_type_ids.bool()][1:-1].softmax(-1)\n","\n","    probability = torch.triu(start_prob[:, None] @ end_prob[None, :])\n","\n","    # 토큰 길이 8까지만\n","    for row in range(len(start_prob) - 8):\n","        probability[row] = torch.cat((probability[row][:8+row].cpu(), torch.Tensor([0] * (len(start_prob)-(8+row))).cpu()), 0)\n","\n","    index = torch.argmax(probability).item()\n","\n","    start = index // len(end_prob)\n","    end = index % len(end_prob)\n","\n","    # 확률 너무 낮으면 자르기\n","    if start_prob[start] >= 0 or end_prob[end] >= 0:\n","        start_str = sample['position'][start][0]\n","        end_str = sample['position'][end][1]\n","    else:\n","        start_str = 0\n","        end_str = 0\n","\n","    start_visualize.append((list(start_prob.cpu()), (start, end), (start_str, end_str)))\n","    end_visualize.append((list(end_prob.cpu()), (start, end), (start_str, end_str)))\n","\n","    dev_prediction.append([sample[\"guid\"], sample['context'][start_str:end_str]])\n"]},{"cell_type":"markdown","metadata":{"tags":[],"id":"0PvIUn_UWOHn"},"source":["## Lenvenshtein"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mn7L7eKJWOHn","executionInfo":{"status":"aborted","timestamp":1650016028769,"user_tz":-540,"elapsed":13,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"outputs":[],"source":["def calc_distance(a, b):\n","    ''' 레벤슈타인 거리 계산하기 '''\n","    if a == b:\n","        return 0 # 같으면 0을 반환\n","    \n","    a_len = len(a) # a 길이\n","    b_len = len(b) # b 길이\n","    if a == \"\":\n","        return b_len\n","    if b == \"\":\n","        return a_len\n","    \n","    matrix = [[] for i in range(a_len+1)]\n","    \n","    for i in range(a_len+1): # 0으로 초기화\n","        matrix[i] = [0 for j in range(b_len+1)]\n","        \n","    # 0일 때 초깃값을 설정\n","    for i in range(a_len+1):\n","        matrix[i][0] = i\n","        \n","    for j in range(b_len+1):\n","        matrix[0][j] = j\n","        \n","    # 표 채우기 --- (※2)\n","    for i in range(1, a_len+1):\n","        ac = a[i-1]\n","        for j in range(1, b_len+1):\n","            bc = b[j-1]\n","            cost = 0 if (ac == bc) else 1\n","            matrix[i][j] = min([\n","                matrix[i-1][j] + 1,     # 문자 삽입\n","                matrix[i][j-1] + 1,     # 문자 제거\n","                matrix[i-1][j-1] + cost # 문자 변경\n","            ])\n","            \n","    return matrix[a_len][b_len]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nGyjNsMBWOHn","executionInfo":{"status":"aborted","timestamp":1650016028769,"user_tz":-540,"elapsed":12,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"outputs":[],"source":["score = []\n","for i in range(int(len(dev_answers))):\n","    s = calc_distance(dev_prediction[i], dev_answers[i][0])\n","    score.append(s)\n","mean(score)"]},{"cell_type":"markdown","metadata":{"id":"Ul-FlUBZY88_"},"source":["## Evaluate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cyVG3J2hu8-s","executionInfo":{"status":"aborted","timestamp":1650016028770,"user_tz":-540,"elapsed":13,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"outputs":[],"source":["start_visualize = []\n","end_visualize = []\n","\n","with torch.no_grad(), open(f'submissions/{args.NAME}.csv', 'w') as fd:\n","    writer = csv.writer(fd)\n","    writer.writerow(['Id', 'Predicted'])\n","\n","    rows = []\n","    # for sample in tqdm(test_dataset, \"Testing\"):\n","    for sample in tqdm(indexed_test_dataset, \"Testing\"):\n","        input_ids, token_type_ids = [torch.tensor(sample[key], dtype=torch.long, device=\"cuda\") for key in (\"input_ids\", \"token_type_ids\")]\n","        # print(sample)\n","    \n","        model.eval()\n","        with torch.no_grad():\n","            output = model(input_ids=input_ids[None, :], token_type_ids=token_type_ids[None, :])\n","\n","        start_logits = output.start_logits\n","        end_logits = output.end_logits\n","        start_logits.squeeze_(0), end_logits.squeeze_(0)\n","\n","        start_prob = start_logits[token_type_ids.bool()][1:-1].softmax(-1)\n","        end_prob = end_logits[token_type_ids.bool()][1:-1].softmax(-1)\n","\n","        probability = torch.triu(start_prob[:, None] @ end_prob[None, :])\n","\n","        # 토큰 길이 8까지만\n","        for row in range(len(start_prob) - 8):\n","            probability[row] = torch.cat((probability[row][:8+row].cpu(), torch.Tensor([0] * (len(start_prob)-(8+row))).cpu()), 0)\n","\n","        index = torch.argmax(probability).item()\n","\n","        start = index // len(end_prob)\n","        end = index % len(end_prob)\n","        \n","        # 확률 너무 낮으면 자르기\n","        if start_prob[start] >= 0 or end_prob[end] >= 0:\n","            start_str = sample['position'][start][0]\n","            end_str = sample['position'][end][1]\n","        else:\n","            start_str = 0\n","            end_str = 0\n","\n","        start_visualize.append((list(start_prob.cpu()), (start, end), (start_str, end_str)))\n","        end_visualize.append((list(end_prob.cpu()), (start, end), (start_str, end_str)))\n","        \n","        rows.append([sample[\"guid\"], sample['context'][start_str:end_str]])\n","\n","    writer.writerows(rows)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x-IeHI04WOHo","executionInfo":{"status":"aborted","timestamp":1650016028770,"user_tz":-540,"elapsed":13,"user":{"displayName":"조현수","userId":"06575509224308139266"}}},"outputs":[],"source":[""]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":["F6uJSyQCSEoa","UEQiDROgVXmg","9hCiOQO4VYqM","eAfQOTuPeuWN"],"machine_shape":"hm","name":"kobigbird_levenshtein.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"nbformat":4,"nbformat_minor":0}